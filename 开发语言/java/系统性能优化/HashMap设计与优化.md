# HashMap设计与优化

## HashMap的实现结构

`哈希表`将键的Hash值映射到内存地址，即根据键获取对应的值，并将其存储到内存地址。也就是说`HashMap`是根据键的`Hash`值来决定对应值的存储位置。通过这种索引方式，HashMap获取数据的速度会非常快。



### Hash地址冲突

两个对象的获取到的Hash值可能一直，这就导致了两个对象拥有了相同的存储地址，这种现象就被称为`哈希冲突`。

- 解决哈希冲突的方式
  - 开放地址法
  - 再哈希函数法
  - 链地址法

#### 开放地址法

当发生哈希冲突时，如果哈希表未被装满，说明在哈希表中必然还有空位置，那么可以把key存在到冲突位置后面的空位置上去。`这种方法存在很多缺点，例如，查找，扩容等`

#### 再哈希法

就是同义词产生地址冲突时，再计算另一个哈希函数地址，知道冲突不在发生，这种方法不易产生`聚集`, 但却增加了计算时间。如果我们不考虑添加元素的时间成本，且对查询元素要求极高，就可以考虑使用这种算法设计。

#### 链地址法

`HashMap`综合考虑了所有因素，采用`链地址法`解决哈希冲突问题。这种方法是采用了`数据(哈希表) + 链表`的数据结构，当发生哈希冲突时，就用一个链表结构存储相同Hash的数据。



## HashMap的重要属性

### Node

Node用于存储具体的`Key-Value`简直对象，并且包含了`next`属性，当有哈希冲突时，会以链表的方式进行数据存储

### 加载因子(loadFactor)和边界值（threshold）

#### 加载因子(loadFactor)

`localFactor`属性时用来简介设置`Entry`数据的存储空间大小。在初始`HashMap`不设置参数的情况下，默认`loadFactory`值为`0.75`

对于链表法的哈希表来说，查找一个元素的平均时间时`O(1+n)`, 这里的`n`指的是遍历链表的长度，因此`加载因子`越大，对空间的利用就越充分，这就意味着链表的长度越长，查找效率也就越低。如果设置的加载因子太小，那么哈希表的数据将过于稀疏，对空间造成严重浪费。

`threshold`是通过初始容量`capacity`和`loadFactor`计算所得，在初始HashMap不设置参数的情况下，边界值默认为`12(capacity=16; threshold = capacity * loadFactor)`. 如果我们在初始化时，设置的初始化容量较小，`HashMap`中Node数据超过边界值，`HashMap`就会调用`resize()`方法重新分配数据，这将会导致`HashMap`的数据复制，迁移另一块内存中去，从而影响`HashMap`效率。



## HashMap添加元素优化

#### put()方法工作原理

- 添加`key-value`到HashMap中
- 根据`key`的`hashCode()`返回值， 在通过`hash()`函数计算出`hash`值
- 通过`putVal`方法中的`(n-1)&hash`决定该node的存储位置。

> `（n-1）& hash`: 这里的`n`代表了哈希表的长度，哈希表的长度一般都是`2的n次幂`， 这样可以保证`(n-1)&hash`的计算得到的索引值总是位于table数据的索引之内。

![img](.\ebc8c027e556331dc327e18feb00c7d9.jpg)

> 在JDK1.8之后，HashMap因为了如黑树数据结构来提升链表的查询效率

这是因为链表的长度超过`8`后，`红黑树的查询效率要比链表高`，所以当链表超过8的时候，HashMap就汇将链表转换为红黑树。

> 红黑树数据结构引入，解决了在链表长度过长时查询数据的性能问题。



## HashMap获取元素优化

当HashMap中值存在数组，而数据中没有`Node`链表时，是`HashMap`查询数据溪能最好的时候，一旦发生大量的哈希冲突，就会产生Node链表，这个时候每次查询元素都可能遍历Node链表，从而降低查询数据的性能。



特别是在链表长度过长的情况下，性能将明显降低，红黑树的使用很好地解决了这个问题，使得查询的平均复杂度降低到了`O(log(N))`, 链表越长，使用红黑树替换后的查询效率提升越明显。

> 我们可以在代码中，通过重写`hasCode()`方法，降低哈希冲突，从而减少链表的产生，高效利用哈希表，达到提高性能的效果



## HashMap扩容优化

在`JDK 1.7`中，HashMap整个扩容过程就是分别取出数组元素，一般该元素是最后一个放入链表中的元素，然后遍历以钙元素为头的单项链表元素，依据每个被遍历元素的hash值计算其在新数组中的下表，然后进行交换。`这样扩容方式会将原来哈希冲突的单向链表尾部编程扩容后单向链表的头部`。



在`JDK1.8`中，HashMap对扩容操作做了优化。由于扩容数据长度是两倍关系，所以对于假设`初始tableSize=4`要扩容到`8`来说就是`0100`到`1000`的变化，在扩容只用判断原来的`hash`值和左移动一位(`newTable的值`)`按位与`操作是`0`或`1`就行，`0`的索引保持不变，`1`索引编程原索引加上扩容前数组。

> 之所以通过这种`与运算`来重新分配索引，是因为hash值本来就是随机的，而hash按位与上`newTable`得到的 `0(扩容前的索引位置)`和`1(扩容前索引位置 + 扩容前数据长度的数值)`就是随机的，所以扩容的过程能把之前哈希冲突的元素再随机分布到不同的索引中去。

